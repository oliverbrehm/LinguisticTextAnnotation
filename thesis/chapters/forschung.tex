% !TEX root = ../ausarbeitung.tex

\chapter{Stand der Forschung}

Die Motivation der Arbeit beruht auf Erkenntnissen zu Behandlungsformen für Lese- Rechtschreibschwäche (LRS). Es wird untersucht wie gut der Prozess des Erzeugens von Übungstexten automatisiert werden kann. Hierfür war das Ziel bei der Entwicklung der App eine möglichst gute User Experience zu bieten. Die Zielgruppe, vorwiegend bestehend aus Lerntherapeuten, Nachhilfelehrern und Eltern betroffener Kinder soll das Programm möglichst intuitiv bedienen können.\\
Im Folgenden werden daher erst die Grundlagen zu LRS erklärt und Ansätze zur Digitalisierung von Übungstexten, z.B. auch ähnliche, bereits vorhandene Software, beschrieben. Danach werden die computerlinguistischen technischen Grundlagen erklärt, die in der Entwicklung der Applikation benötigt werden.

\section{Lese- Rechtschreibschwäche}

Ein Ausgangspunkt zur Feststellung von LRS bietet die Lesekompetenz. Eine Definition aus der PISA Studie \tocite{PISA, SK s51} untergliedert die Lesekompetenz in die vier Teilbereiche \textit{Kognitive Grundfähigkeit}, \textit{Dekodierfähigkeit}, \textit{Lernstrategiewissen} und \textit{Leseinteresse}.\\
Der Teilbereich, zu dessen Verbesserung diese Arbeit einen Beitrag leisten kann ist die Dekodierfähigkeit. Diese Stellt die Kompetenz dar, die Bedeutung von Wörtern, Sätzen und Texten zu erfassen und zu verstehen. Die Unterteilung in dei Elemente Wort, Satz und Text stellt eine Dekodierungsfähigkeit auf verschiedenen Ebenen dar, die sich gegenseitig bedingen. Das Wort ist hier die Basisebene, so kann ein Text nur verstanden werden, wenn die Bedeutung der einzelnen Sätze erfasst wurde und diese wiederum wird nur erkannt, wenn eine Ausreichende Dekodierfähigkeit für Wörter vorhanden ist.\\
Somit ist eine Vorraussetzung für die Verbesserung des Textverständnis, dass das Erkennen des Basiselements Wort beherrscht wird.

\subsection{Dekodierung des Wortbildes}

Es ist bekannt, dass Kinder der Entwicklung des Lesens und des Schreibens verschiedene Phasen durchlaufen. \tocite{quelle hier sehr weit weg (steinbrink), vielleicht frueher bringen, weitere quelle} So gibt in jedem Fall eine alphabetische und eine orthographische Phase. Beim Lesen wird in der alphabetischen Phase ein Wort Buchstabe für Buchstabe dekodiert, \textit{Grapheme} (die kleinste Einheit in der Schriftsprache, in deutsch Buchstaben) werden einzeln in \textit{Phoneme} (Laute, die kleinste Einheit der gesprochenen Sprache) umgewandelt, was aber bei nicht lautgetreuen Wörtern (Wörtern, in denen nicht alle Grapheme korrekt in die zugehörigen Phoneme übersetzen lassen) nicht gelingt.\\
Daher wird später in der orthographischen Phase eine Strategie benutzt, die sich an größeren Bestandteilen orientiert. Wörter oder Wortteile werden hier aus dem Langzeitgedächtnis abgerufen, was bei richtig gelernten Silben und Wörtern zu korrekter Aussprache führt. \cite{Steinbrink2014}\\
Einige schulische Ansätze fördern das orthographische Lernen mit einer gezielten Hervorhebung von Silben. \tocite{ABC der Tiere, Silbenfibeln}. \todo{mehr dekodierung stuff} Viele Fördermaterialien sind erhältlich, die Silben beispielsweise farblich hervorheben und damit guten Lernerfolg erzielen. \tocite{ABC}
Weiterführende Arbeiten legen aber auch nahe, dass der Sprachrhythmus eine zentrale Rollen sowohl beim Lesen als auch beim Schreiben spielt. So hat ein Wort in der deutschen Sprache eine oder mehrere Betonungen. Betonte Silben werden, im Gegensatz zu den unbetonten Silben lauter und länger gesprochen. Es wurde gezeigt, dass gezieltes Training des Sprachrhythmus in Verbindung mit der orthographischen Repräsentation eines Wortes die Dekodierfähigkeit steigern kann. \cite{Brandelik2014}
\todo{more betonung stuff}

warum ist zeicheinabstand wichtig? mehr zu font, textgröße, wortabstand... -> Katharina?

\subsection{Therapiemethoden}

Wie kann LRS sonst noch behandelt werden?\\
Methoden zum Lesetraining\\
Farbliche Hervorhebung, Silbenmethode ABC der Tiere, andere quellen
Literatur zu übungen\\

\subsection{Digitale Ansätze}
Vorhandene Methoden\\
ABC der Tiere software, CELESCO ( https://www.celeco.de/?page=LRS\_Texte\_mit\_Silbenboegen\_drucken)
Digitale Tools\\

vorhandene tools vorstellen, Literatur zu Tools, zeigen, wie diese Ideen weitergeführt werden können, übergang zur notwendigkeit des eigenen tools\\

\section{Computerlinguistische Grundlagen}

Um das Ziel einer automatischen Analyse und Annotation beliebiger Texte zu realisieren, werden computerlinguistisch vor Allem die folgenden zwei Schritte untersucht:
\begin{enumerate}
	\item Linguistische Analyse (Zerlegung des Texts Wörter)
	\item Nachschlagen der Betonungsmuster in einer Datenbank
\end{enumerate}

\subsection{Linguistische Analyse}
Da die vom Programm zu verarbeitende Eingabe ein Text ist, also eine beliebige Folge von alphanumerischen Zeichen, sowie Leerraumzeichen und Interpunktionen, muss diese Eingabe zunächst korrekt in Wörter zerteilt werden. Dieser Schritt wird \textbf{Tokenisierung} genannt. Zusätzlich werden auch von einem \textbf{Tagger} jedem Wort weitere Informationen, wie z.B. die Wortart (\textit{Part-of-Speech/POS-Tagger}) hinzugefügt. Diese werden üblicherweise mithilfe eines entsprechenden Lexikons nachgeschlagen. \cite{Carstensen2009}\todo{2. auflage 2014, S. 218-220, 224-226} Der für dieses Projekt verwendete Parser wird in Abschnitt \toref{spacy} näher beschrieben.

\todo{Lemma, was ist das}\\

\subsection{Datenbanken zur Wortbetoung}
Nachdem der Text als Liste von Wörtern (Tokens) vorliegt kann auf dieser Ebene weitergearbeitet werden. Für die gewünschte Annotation des Textes muss eine Repräsentation in einzelnen Silben vorliegen. Zusätzlich wird für die Hervorhebung des Sprachrhythlmus die betonte Silbe im Wort gesucht. Es ist durchaus möglich, dass in einem Wort mehrere Betonungen vorkommen (gerade bei Wortkompositionen, die im Deutschen häufig zu finden sind, z.B. \textit{heraus+kommen}). Dies wird in der vorliegenden Arbeit vernachlässigt, es wird nur eine Hauptbetonung, die erste vorkommende Betonung im Wort, gesucht.\\
Informationen zur Worttrennung in Silben und zur Wortbetonung lassen sich in diversen Lexika finden. Für die weitere Verwendung in der zu entwickelnden Applikation wurde als Grundlage das Lexikon CELEX2 gewählt. Dabei handelt es sich um ein umfangreiches Sprachlexikon für die Sprachen Englisch, Deutsch und Niederländisch. Verarbeitet wurden hier zunächst nur die deutsche Sprache. Neben der gesuchten Worttrennung und -betonung enthält es auch weitere linguistische Informationen wie Wortart und Grundformen sowie phonologische und orthographische Annotationen.
\todo{Alternativen, welche? könnten zusätzlich oder anstelle des CELEX verwendet werden}\\
Weiterführend wurden auch Text-To-Speech Systeme untersucht. Diese müssen um zu funktionieren zwangsweise eine phonologische Analyse durchführen, also auch die Wortbetonung bestimmen. Beispielsweise liefern die Systeme MARY TTS\tocite{MARY, woher?} oder BAS\tocite{BAS} auch textuellen annotiere Formen ihrer phonologischen Analyse, die auch als Grundlage zur Extraktion von Worttrennung und Betonung dienen können.\\

Linguistische Datenbanken sind aufgrund des Umfangs und der Flexibilität von Sprachgrammatiken niemals vollständig\tocite{lixika, datenbanken}. Es wurde daher ein Weg gesucht die Datenbank auf unkomplizierte Weise erweiterbar zu machen. Dies kann mit einem geeignete User-Interface durch Experten erfolgen, die unbekannte Einträge ergänzen und hinzufügen. Einige Arbeiten hatten bereits Erfolg damit, solche Aufgaben effektiv auch auf Nutzer zu verteilen, die keine Experten für den jeweiligen Anwendungsbereich sind. Auf Plattformen wie Amazon Mechanical Turc oder CrowdFlower können beispielsweise leicht Arbeiter anonym engagiert werden, die solche Aufgaben erledigen\cite{Snow2008}. Diese Plattformen wurden beispielsweise von Zaidan (Übersetzungen)\cite{Zaidan2011} oder Meurers\cite{Meurers2015} (\todo{wofür?}) benutzt, um computerlinguistische Aufgaben zu erledigen.